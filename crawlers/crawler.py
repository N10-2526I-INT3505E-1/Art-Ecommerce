import requests
from bs4 import BeautifulSoup
import time
import random
import json
import unicode

# Link trang danh m·ª•c (v√≠ d·ª•: Tranh phong c·∫£nh v√πng cao)
BASE_URL = "https://bantranh.com"
LIST_URL = "https://bantranh.com/pc/tranh-phong-canh-vung-cao/page/{}/" # Trang n√†y c√≥ th·ªÉ kh√¥ng ph√¢n trang ki·ªÉu ?page=1, c·∫ßn ki·ªÉm tra k·ªπ
API_URL = "http://localhost:3000/products"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# --- T·ª™ ƒêI·ªÇN PHONG TH·ª¶Y (ƒê·ªÉ sinh Tags cho AI) ---
TAG_RULES = {

    # ============================
    # 1. NG≈® H√ÄNH (Phong th·ªßy)
    # ============================
    "hoa": [
        "m√£ ƒë√°o", "ng·ª±a", "m·∫∑t tr·ªùi", "hoa m·∫´u ƒë∆°n", "h∆∞·ªõng d∆∞∆°ng",
        "ƒë·ªè", "cam", "l·ª≠a", "ho√†ng h√¥n", "ph∆∞·ª£ng ho√†ng", "nhi·ªát",
    ],
    "thuy": [
        "c·ª≠u ng∆∞", "c√° koi", "bi·ªÉn", "thuy·ªÅn", "thu·∫≠n bu·ªìm", "s√¥ng",
        "su·ªëi", "th√°c n∆∞·ªõc", "m·∫∑t h·ªì", "sen", "m∆∞a", "xanh d∆∞∆°ng",
    ],
    "moc": [
        "c√¢y", "r·ª´ng", "t√πng", "tr√∫c", "c√∫c", "mai", "ƒë√†o", "l√°",
        "xanh l√°", "ƒë·ªìi n√∫i xanh", "v√πng cao", "ru·ªông b·∫≠c thang",
    ],
    "kim": [
        "chim c√¥ng", "d√°t v√†ng", "b·∫°c", "tr·∫Øng", "thi√™n nga", "tuy·∫øt",
        "h·∫°c", "hoa vƒÉn kim lo·∫°i",
    ],
    "tho": [
        "n√∫i", "non b·ªô", "l√†ng qu√™", "ƒë·∫•t", "ru·ªông", "b·∫≠c thang",
        "ƒë√°", "tr√¢u", "c·ªïng l√†ng", "t∆∞·ªùng ƒë√°", "n√¢u",
    ],

    # =======================================
    # 2. CH·ª¶ ƒê·ªÄ TRANH (Theo danh m·ª•c Website)
    # =======================================
    "phong_canh": [
        "phong c·∫£nh", "v√πng cao", "ru·ªông b·∫≠c thang", "n√∫i non",
        "r·ª´ng c√¢y", "ƒë·ªìi", "s√¥ng su·ªëi", "bi·ªÉn", "th√°c n∆∞·ªõc",
        "ho√†ng h√¥n", "b√¨nh minh", "l√†ng qu√™", "c·∫£nh ƒë·ªìng qu√™",
    ],
    "truu_tuong": [
        "tr·ª´u t∆∞·ª£ng", "abstract", "m·∫£ng m√†u", "h√¨nh h·ªçc",
        "art line", "t·ªëi gi·∫£n", "h√¨nh kh·ªëi",
    ],
    "dong_vat": [
        "ng·ª±a", "h·ªï", "voi", "chim c√¥ng", "h∆∞∆°u", "c√° koi",
        "r·ªìng", "ƒë·∫°i b√†ng", "chim", "thi√™n nga", "s√≥i",
    ],
    "phong_thuy": [
        "thu·∫≠n bu·ªìm", "b√¨nh an", "t√†i l·ªôc", "ph√°t t√†i",
        "m√£ ƒë√°o th√†nh c√¥ng", "c·ª≠u ng∆∞", "ch·ªØ ph√∫c", "hoa sen",
    ],
    "phat_giao": [
        "ph·∫≠t", "qu√°n th·∫ø √¢m", "b·ªì t√°t", "thi·ªÅn", "an y√™n",
    ],
    "dong_ho": [
        "tranh ƒë√¥ng h·ªì", "d√¢n gian", "g√†", "ƒë√°m c∆∞·ªõi chu·ªôt", "l·ª£n",
    ],
    "hoa_la": [
        "hoa sen", "m·∫´u ƒë∆°n", "c√∫c", "ƒë√†o", "hoa h·ªìng",
        "tulip", "l√° c√¢y", "tƒ©nh v·∫≠t hoa",
    ],
    "thon_da": [
        "l√†ng qu√™", "ƒë·ªìng l√∫a", "s√¢n ƒë√¨nh", "c·ªïng l√†ng",
        "tr√¢u", "tre l√†ng",
    ],
    "thien_nhien": [
        "hoa", "l√°", "c√¢y", "n√∫i", "bi·ªÉn", "m√¢y", "r·ª´ng",
    ],
    "canh_thien_nhien_chau_a": [
        "h·∫° long", "sapa", "ninh b√¨nh", "tr∆∞·ªùng th√†nh", "japan",
        "ch√πa", "ƒë·ªÅn", "c·ªïng torii",
    ],

    # ======================================
    # 3. √ù NGHƒ®A PHONG TH·ª¶Y (Ng∆∞·ªùi mua hay h·ªèi)
    # ======================================
    "tai_loc": [
        "c·ª≠u ng∆∞", "thuy·ªÅn", "thu·∫≠n bu·ªìm", "v√†ng", "l√∫a ch√≠n",
        "m√πa g·∫∑t", "c√°", "ƒë·ªìng ti·ªÅn", "r·ªìng v√†ng",
    ],
    "cong_danh": [
        "m√£ ƒë√°o", "ƒë·∫°i b√†ng", "r·ªìng", "b·∫°ch h·ªï",
        "ƒë·ªânh n√∫i", "m·∫∑t tr·ªùi",
    ],
    "binh_an": [
        "ph·∫≠t", "hoa sen", "l√†ng qu√™", "c√°nh ƒë·ªìng", "tr√∫c",
        "√°nh s√°ng nh·∫π", "thi·ªÅn",
    ],
    "suc_khoe": [
        "c√¢y xanh", "n∆∞·ªõc ch·∫£y", "sen", "r·ª´ng", "n·∫Øng nh·∫π",
    ],
    "tinh_duyen": [
        "ƒë√¥i", "uy√™n ∆∞∆°ng", "m·∫´u ƒë∆°n", "chim c√¥ng", "thi√™n nga",
    ],

    # ====================
    # 4. PHONG C√ÅCH TRANH
    # ====================
    "hien_dai": [
        "hi·ªán ƒë·∫°i", "3d", "scandinavian", "t·ªëi gi·∫£n",
        "b·∫Øc √¢u", "geometric", "abstract", "line art",
    ],
    "co_dien": [
        "c·ªï ƒëi·ªÉn", "s∆°n d·∫ßu", "s∆°n m√†i", "s∆°n th·ªßy",
        "th·ªßy m·∫∑c", "ƒë√¥ng h·ªì",
    ],
    "lang_man": [
        "m√πa thu", "l√° v√†ng", "paris", "ch√¢u √¢u", "hoa h·ªìng",
        "√°nh ƒë√®n", "couple",
    ],
    "toi_gian": [
        "minimal", "ƒë∆°n s·∫Øc", "line art", "geometry",
    ],

    # =========================
    # 5. M√ÄU S·∫ÆC (Color Tags)
    # =========================
    "mau_sac": [
        "tr·∫Øng", "ƒëen", "x√°m", "n√¢u", "v√†ng", "cam",
        "ƒë·ªè", "t√≠m", "xanh d∆∞∆°ng", "xanh l√°",
        "pastel", "gold", "silver",
    ],

    # ================================
    # 6. KH√îNG GIAN TREO (Interior)
    # ================================
    "phong_khach": [
        "sofa", "living room", "kh·ªï l·ªõn", "panorama", "ƒëa t·∫•m",
    ],
    "phong_ngu": [
        "gi∆∞·ªùng", "bedroom", "√™m d·ªãu", "m√†u pastel",
        "hoa nh·∫π", "tƒ©nh l·∫∑ng",
    ],
    "phong_lam_viec": [
        "b√†n l√†m vi·ªác", "bookshelf", "ƒë·ªông l·ª±c", "nƒÉng l∆∞·ª£ng m·∫°nh",
    ],
    "phong_an": [
        "b√†n ƒÉn", "·∫•m √°p", "hoa qu·∫£", "tƒ©nh v·∫≠t",
    ],
    "cau_thang": [
        "d·ªçc", "vertical", "1 t·∫•m d√†i", "tr·ª´u t∆∞·ª£ng",
    ],

    # ===============================
    # 7. C·∫¢M X√öC / TONE (Mood Tags)
    # ===============================
    "cam_xuc": [
        "b√¨nh y√™n", "tƒ©nh l·∫∑ng", "m·∫°nh m·∫Ω", "nƒÉng l∆∞·ª£ng",
        "·∫•m √°p", "sang tr·ªçng", "l√£ng m·∫°n", "ho√†i c·ªï",
        "t∆∞∆°i s√°ng", "minimal", "vintage", "huy·ªÅn b√≠",
    ],

    # ======================
    # 8. CH·∫§T LI·ªÜU TRANH
    # ======================
    "chat_lieu": [
        "canvas", "s∆°n d·∫ßu", "s∆°n m√†i", "g·∫°o", "g·ªó",
        "k√≠nh", "mica", "d√°t v√†ng", "in uv", "tranh b·ªô 3",
    ],

    # =======================================
    # 9. ƒê·∫∂C ƒêI·ªÇM B·ªê C·ª§C (Composition Tags)
    # =======================================
    "bo_cuc": [
        "c√¢n b·∫±ng", "ƒë·ªëi x·ª©ng", "b·∫•t ƒë·ªëi x·ª©ng", "ƒëu·ªïi g√≥c",
        "leading lines", "1 ƒëi·ªÉm t·ª•", "nhi·ªÅu l·ªõp", "chi·ªÅu s√¢u",
        "√°nh s√°ng m·∫°nh", "√°nh s√°ng nh·∫π",
    ],

    # =====================================
    # 10. V·ªä TR√ç ‚Äì H∆Ø·ªöNG TREO PHONG TH·ª¶Y
    # =====================================
    "huong_treo": [
        "ƒë·∫ßu ng·ª±a quay v√†o nh√†",
        "m≈©i thuy·ªÅn h∆∞·ªõng v√†o nh√†",
        "n√∫i treo ph√≠a sau gh·∫ø",
        "c√° h∆∞·ªõng v√†o trong",
        "√°nh s√°ng h∆∞·ªõng v√†o t√¢m nh√†",
    ],
}

PHONG_THUY_KEYS = ["hoa", "thuy", "moc", "kim", "tho"]
INTENT_KEYS = ["tai_loc", "cong_danh", "binh_an", "tinh_duyen", "suc_khoe"]
STYLE_KEYS = ["hien_dai", "co_dien", "lang_man", "toi_gian"]
SPACE_KEYS = ["phong_khach", "phong_ngu", "phong_lam_viec", "phong_an", "cau_thang"]
COLOR_KEYS = ["mau_sac"]
MOOD_KEYS = ["cam_xuc"]
COMPOSITION_KEYS = ["bo_cuc"]
MATERIAL_KEYS = ["chat_lieu"]
TOPIC_KEYS = [
    "phong_canh", "truu_tuong", "dong_vat", "phong_thuy",
    "phat_giao", "dong_ho", "hoa_la", "thon_da",
    "thien_nhien", "canh_thien_nhien_chau_a"
]


def normalize(txt: str):
    return unidecode.unidecode(txt.lower())

def generate_tags(text):
    text = normalize(text)
    tags = []

    for key, keywords in TAG_RULES.items():
        for kw in keywords:
            if normalize(kw) in text:

                # 1. Ng≈© h√†nh
                if key in PHONG_THUY_KEYS:
                    tags.append(f"menh_{key}")  # v√≠ d·ª•: menh_moc, menh_hoa
                    break

                # 2. √ù nghƒ©a phong th·ªßy
                elif key in INTENT_KEYS:
                    tags.append(f"y_nghia_{key}")
                    break

                # 3. Ch·ªß ƒë·ªÅ
                elif key in TOPIC_KEYS:
                    tags.append(f"chu_de_{key}")
                    break

                # 4. Phong c√°ch n·ªôi th·∫•t
                elif key in STYLE_KEYS:
                    tags.append(f"phong_cach_{key}")
                    break

                # 5. Kh√¥ng gian treo
                elif key in SPACE_KEYS:
                    tags.append(f"khong_gian_{key}")
                    break

                # 6. M√†u s·∫Øc
                elif key in COLOR_KEYS:
                    tags.append(f"mau_{kw}")
                    break

                # 7. C·∫£m x√∫c
                elif key in MOOD_KEYS:
                    tags.append(f"cam_xuc_{kw}")
                    break

                # 8. B·ªë c·ª•c
                    tags.append(f"bo_cuc_{key}")
                    break

                # 9. Ch·∫•t li·ªáu
                elif key in MATERIAL_KEYS:
                    tags.append(f"chat_lieu_{kw}")
                    break

    return list(set(tags))

# ----------------------------------------
# 1. Crawler
# ----------------------------------------
def get_product_links(page):
    print(f"üü¶ ƒêang t·∫£i trang danh s√°ch: {LIST_URL}")
    url = LIST_URL.format(page)
    res = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(res.text, "html.parser")

    product_links = []

    cnt = 0
    copy_href = ""
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if "/pd" in href and copy_href != href:
            print(href)
            product_links.append(href)
            copy_href = href
            cnt += 1
    print(cnt)
        
    return product_links[:1]

def get_product_detail(url):
    time.sleep(random.uniform(0.5, 1.5))
    res = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(res.text, "html.parser")

    title = soup.find("h1")
    title = title.text.strip() if title else "Untitle"

    price_tag = soup.select_one(".price") # Class .price ph·ªï bi·∫øn ·ªü bantranh.com
    price_raw = price_tag.text.strip() if price_tag else "0"
    
    try:
        clean_price = float(price_raw.replace('.', '').replace(',', '').replace('‚Ç´', '').replace('vnƒë', '').strip())
    except:
        clean_price = 0.0

    img_tag = soup.find("img", class_="wp-post-image skip-lazy")
    img_url = img_tag["src"] if img_tag else ""
    if img_url and not img_url.startswith("http"):
        img_url = "https:" + img_url # X·ª≠ l√Ω n·∫øu link thi·∫øu https

    category = "tranh phong c·∫£nh v√πng cao"
    auto_tags = generate_tags(f"{title} {category}")

    return {
        "name": title,
        "price": clean_price,
        "imageUrl": img_url,
        "categoryName": category,
        "tags": auto_tags,
        "description": f"Crawl from {url}",
        "sourceUrl": url
    }

links = get_product_links(1)
print(links)
print(f"Find {len(links)} products")

for link in links:
    print("-> crawl:", link)
    try:
        data=get_product_detail(link)
        print(json.dumps(data, ensure_ascii=False, indent=2))


        resp = requests.post(API_URL, json=data)
        if resp.status_code != 201:
            print(f"    ‚ùå L·ªói API: {resp.text}")
    except Exception as e:
        print(e)
    
    


